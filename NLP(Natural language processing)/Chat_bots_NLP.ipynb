{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fedf06d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba523124",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_qa.txt', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0871005",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_qa.txt', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c446d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary got the milk there . John moved to the bedroom .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e209ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_data =  train_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e37d6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whole_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c10fd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "\n",
    "for story,question,answer in whole_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))\n",
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4185ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ced24be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99f7257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_story_len = [len(data[0]) for data in whole_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb8a37ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12,\n",
       " 23,\n",
       " 35,\n",
       " 47,\n",
       " 59,\n",
       " 13,\n",
       " 26,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 60,\n",
       " 12,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 47,\n",
       " 59,\n",
       " 12,\n",
       " 25,\n",
       " 36,\n",
       " 48,\n",
       " 59,\n",
       " 12,\n",
       " 26,\n",
       " 39,\n",
       " 51,\n",
       " 63,\n",
       " 13,\n",
       " 24,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 13,\n",
       " 26,\n",
       " 38,\n",
       " 50,\n",
       " 63,\n",
       " 13,\n",
       " 25,\n",
       " 36,\n",
       " 49,\n",
       " 61,\n",
       " 13,\n",
       " 26,\n",
       " 39,\n",
       " 51,\n",
       " 64,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 50,\n",
       " 61,\n",
       " 12,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 25,\n",
       " 37,\n",
       " 50,\n",
       " 61,\n",
       " 12,\n",
       " 25,\n",
       " 36,\n",
       " 48,\n",
       " 60,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 60,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 60,\n",
       " 13,\n",
       " 25,\n",
       " 39,\n",
       " 51,\n",
       " 64,\n",
       " 12,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 12,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 61,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 49,\n",
       " 62,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 23,\n",
       " 35,\n",
       " 47,\n",
       " 59,\n",
       " 12,\n",
       " 25,\n",
       " 37,\n",
       " 48,\n",
       " 73,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 62,\n",
       " 14,\n",
       " 26,\n",
       " 37,\n",
       " 49,\n",
       " 62,\n",
       " 12,\n",
       " 23,\n",
       " 35,\n",
       " 48,\n",
       " 59,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 49,\n",
       " 61,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 12,\n",
       " 25,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 47,\n",
       " 58,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 61,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 74,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 60,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 61,\n",
       " 12,\n",
       " 25,\n",
       " 36,\n",
       " 50,\n",
       " 62,\n",
       " 24,\n",
       " 36,\n",
       " 49,\n",
       " 61,\n",
       " 74,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 47,\n",
       " 59,\n",
       " 13,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 61,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 48,\n",
       " 61,\n",
       " 13,\n",
       " 26,\n",
       " 39,\n",
       " 52,\n",
       " 63,\n",
       " 13,\n",
       " 27,\n",
       " 40,\n",
       " 51,\n",
       " 63,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 59,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 47,\n",
       " 58,\n",
       " 12,\n",
       " 23,\n",
       " 35,\n",
       " 47,\n",
       " 59,\n",
       " 12,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 35,\n",
       " 47,\n",
       " 60,\n",
       " 13,\n",
       " 26,\n",
       " 38,\n",
       " 51,\n",
       " 63,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 61,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 60,\n",
       " 13,\n",
       " 25,\n",
       " 38,\n",
       " 49,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 35,\n",
       " 47,\n",
       " 59,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 58,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 61,\n",
       " 13,\n",
       " 26,\n",
       " 38,\n",
       " 50,\n",
       " 63,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 62,\n",
       " 74,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 49,\n",
       " 61,\n",
       " 13,\n",
       " 26,\n",
       " 39,\n",
       " 51,\n",
       " 63,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 60,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 47,\n",
       " 59,\n",
       " 13,\n",
       " 26,\n",
       " 38,\n",
       " 51,\n",
       " 64,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 51,\n",
       " 63,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 25,\n",
       " 38,\n",
       " 48,\n",
       " 60,\n",
       " 12,\n",
       " 25,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 13,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 63,\n",
       " 12,\n",
       " 23,\n",
       " 36,\n",
       " 49,\n",
       " 61,\n",
       " 13,\n",
       " 24,\n",
       " 37,\n",
       " 60,\n",
       " 71,\n",
       " 12,\n",
       " 24,\n",
       " 35,\n",
       " 47,\n",
       " 60,\n",
       " 12,\n",
       " 24,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 36,\n",
       " 48,\n",
       " 61,\n",
       " 73,\n",
       " 86,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 60,\n",
       " 13,\n",
       " 25,\n",
       " 36,\n",
       " 47,\n",
       " 59,\n",
       " 13,\n",
       " 25,\n",
       " 38,\n",
       " 49,\n",
       " 62,\n",
       " 24,\n",
       " 37,\n",
       " 48,\n",
       " 60,\n",
       " 72,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 62,\n",
       " 12,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 23,\n",
       " 35,\n",
       " 49,\n",
       " 60,\n",
       " 14,\n",
       " 26,\n",
       " 39,\n",
       " 51,\n",
       " 63,\n",
       " 13,\n",
       " 25,\n",
       " 36,\n",
       " 49,\n",
       " 62,\n",
       " 13,\n",
       " 26,\n",
       " 38,\n",
       " 50,\n",
       " 61,\n",
       " 13,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 13,\n",
       " 26,\n",
       " 39,\n",
       " 51,\n",
       " 63,\n",
       " 12,\n",
       " 25,\n",
       " 47,\n",
       " 61,\n",
       " 74,\n",
       " 13,\n",
       " 26,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 49,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 12,\n",
       " 25,\n",
       " 37,\n",
       " 50,\n",
       " 61,\n",
       " 12,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 63,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 60,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 62,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 49,\n",
       " 60,\n",
       " 25,\n",
       " 36,\n",
       " 48,\n",
       " 61,\n",
       " 73,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 60,\n",
       " 12,\n",
       " 24,\n",
       " 35,\n",
       " 47,\n",
       " 60,\n",
       " 12,\n",
       " 25,\n",
       " 38,\n",
       " 51,\n",
       " 65,\n",
       " 12,\n",
       " 25,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 35,\n",
       " 48,\n",
       " 61,\n",
       " 13,\n",
       " 27,\n",
       " 39,\n",
       " 51,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 48,\n",
       " 60,\n",
       " 13,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 62,\n",
       " 12,\n",
       " 23,\n",
       " 35,\n",
       " 47,\n",
       " 59,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 49,\n",
       " 61,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 73,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 13,\n",
       " 26,\n",
       " 38,\n",
       " 50,\n",
       " 61,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 49,\n",
       " 61,\n",
       " 27,\n",
       " 38,\n",
       " 50,\n",
       " 61,\n",
       " 73,\n",
       " 12,\n",
       " 26,\n",
       " 37,\n",
       " 50,\n",
       " 63,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 59,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 48,\n",
       " 60,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 48,\n",
       " 61,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 60,\n",
       " 12,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 63,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 61,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 14,\n",
       " 27,\n",
       " 39,\n",
       " 51,\n",
       " 62,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 60,\n",
       " 12,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 63,\n",
       " 24,\n",
       " 36,\n",
       " 47,\n",
       " 59,\n",
       " 71,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 13,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 61,\n",
       " 23,\n",
       " 34,\n",
       " 46,\n",
       " 58,\n",
       " 70,\n",
       " 13,\n",
       " 25,\n",
       " 38,\n",
       " 52,\n",
       " 65,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 47,\n",
       " 60,\n",
       " 12,\n",
       " 26,\n",
       " 38,\n",
       " 51,\n",
       " 63,\n",
       " 12,\n",
       " 25,\n",
       " 38,\n",
       " 49,\n",
       " 62,\n",
       " 13,\n",
       " 25,\n",
       " 38,\n",
       " 49,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 49,\n",
       " 61,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 38,\n",
       " 51,\n",
       " 63,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 62,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 12,\n",
       " 24,\n",
       " 38,\n",
       " 50,\n",
       " 61,\n",
       " 35,\n",
       " 47,\n",
       " 60,\n",
       " 72,\n",
       " 84,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 49,\n",
       " 61,\n",
       " 12,\n",
       " 24,\n",
       " 35,\n",
       " 48,\n",
       " 60,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 49,\n",
       " 60,\n",
       " 12,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 60,\n",
       " 13,\n",
       " 26,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 13,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 64,\n",
       " 23,\n",
       " 35,\n",
       " 47,\n",
       " 60,\n",
       " 73,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 49,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 12,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 14,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 13,\n",
       " 26,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 23,\n",
       " 35,\n",
       " 47,\n",
       " 58,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 25,\n",
       " 36,\n",
       " 48,\n",
       " 60,\n",
       " 71,\n",
       " 24,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 75,\n",
       " 13,\n",
       " 25,\n",
       " 36,\n",
       " 47,\n",
       " 59,\n",
       " 24,\n",
       " 37,\n",
       " 50,\n",
       " 61,\n",
       " 74,\n",
       " 12,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 64,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 48,\n",
       " 61,\n",
       " 12,\n",
       " 25,\n",
       " 38,\n",
       " 51,\n",
       " 64,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 49,\n",
       " 60,\n",
       " 12,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 25,\n",
       " 39,\n",
       " 51,\n",
       " 63,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 49,\n",
       " 61,\n",
       " 12,\n",
       " 26,\n",
       " 39,\n",
       " 51,\n",
       " 63,\n",
       " 13,\n",
       " 26,\n",
       " 38,\n",
       " 49,\n",
       " 60,\n",
       " 37,\n",
       " 48,\n",
       " 60,\n",
       " 73,\n",
       " 83,\n",
       " 12,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 61,\n",
       " 13,\n",
       " 25,\n",
       " 38,\n",
       " 51,\n",
       " 64,\n",
       " 12,\n",
       " 25,\n",
       " 39,\n",
       " 51,\n",
       " 63,\n",
       " 23,\n",
       " 36,\n",
       " 47,\n",
       " 59,\n",
       " 71,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 13,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 36,\n",
       " 47,\n",
       " 59,\n",
       " 71,\n",
       " 84,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 25,\n",
       " 37,\n",
       " 51,\n",
       " 63,\n",
       " 13,\n",
       " 26,\n",
       " 38,\n",
       " 52,\n",
       " 64,\n",
       " 12,\n",
       " 24,\n",
       " 37,\n",
       " 49,\n",
       " 60,\n",
       " 12,\n",
       " 24,\n",
       " 36,\n",
       " 47,\n",
       " 60,\n",
       " 13,\n",
       " 25,\n",
       " 36,\n",
       " 49,\n",
       " 61,\n",
       " 13,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 12,\n",
       " 24,\n",
       " 38,\n",
       " 51,\n",
       " 63,\n",
       " 13,\n",
       " 25,\n",
       " 38,\n",
       " 50,\n",
       " 62,\n",
       " 13,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 60,\n",
       " 12,\n",
       " 25,\n",
       " 36,\n",
       " 47,\n",
       " 60,\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of all stories\n",
    "all_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3e6ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of the longest story \n",
    "max_story_len = max(all_story_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98f18f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_question_len = [len(data[0]) for data in whole_data]\n",
    "max_question_len = max(all_question_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48bcdbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd8eea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe2ed03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 1,\n",
       " 'the': 2,\n",
       " 'in': 3,\n",
       " 'bedroom': 4,\n",
       " 'bathroom': 5,\n",
       " 'to': 6,\n",
       " 'left': 7,\n",
       " 'discarded': 8,\n",
       " 'travelled': 9,\n",
       " 'john': 10,\n",
       " 'moved': 11,\n",
       " 'garden': 12,\n",
       " 'went': 13,\n",
       " 'picked': 14,\n",
       " 'dropped': 15,\n",
       " 'apple': 16,\n",
       " 'office': 17,\n",
       " 'daniel': 18,\n",
       " 'hallway': 19,\n",
       " 'back': 20,\n",
       " 'grabbed': 21,\n",
       " '.': 22,\n",
       " 'milk': 23,\n",
       " 'no': 24,\n",
       " 'got': 25,\n",
       " 'yes': 26,\n",
       " 'put': 27,\n",
       " 'is': 28,\n",
       " 'up': 29,\n",
       " '?': 30,\n",
       " 'down': 31,\n",
       " 'football': 32,\n",
       " 'mary': 33,\n",
       " 'journeyed': 34,\n",
       " 'there': 35,\n",
       " 'kitchen': 36,\n",
       " 'sandra': 37}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f810992",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text= []\n",
    "train_answers =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79e6d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question, answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0a2c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d58bc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44e52a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_stories(data,word_index= tokenizer.word_index,max_story_len= max_story_len,max_question_len=max_question_len):\n",
    "    X =[]\n",
    "    Xq =[]\n",
    "    Y=[]\n",
    "    for story,query,answer in data:\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        y = np.zeros(len(word_index)+1)\n",
    "        y[word_index[answer]]=1\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "    return (pad_sequences(X,maxlen= max_story_len),pad_sequences(Xq,maxlen= max_question_len),np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49a9e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, query_train, answer_train = vector_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff2e5457",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, query_test, answer_test = vector_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3b82a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25d94908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 1,\n",
       " 'the': 2,\n",
       " 'in': 3,\n",
       " 'bedroom': 4,\n",
       " 'bathroom': 5,\n",
       " 'to': 6,\n",
       " 'left': 7,\n",
       " 'discarded': 8,\n",
       " 'travelled': 9,\n",
       " 'john': 10,\n",
       " 'moved': 11,\n",
       " 'garden': 12,\n",
       " 'went': 13,\n",
       " 'picked': 14,\n",
       " 'dropped': 15,\n",
       " 'apple': 16,\n",
       " 'office': 17,\n",
       " 'daniel': 18,\n",
       " 'hallway': 19,\n",
       " 'back': 20,\n",
       " 'grabbed': 21,\n",
       " '.': 22,\n",
       " 'milk': 23,\n",
       " 'no': 24,\n",
       " 'got': 25,\n",
       " 'yes': 26,\n",
       " 'put': 27,\n",
       " 'is': 28,\n",
       " 'up': 29,\n",
       " '?': 30,\n",
       " 'down': 31,\n",
       " 'football': 32,\n",
       " 'mary': 33,\n",
       " 'journeyed': 34,\n",
       " 'there': 35,\n",
       " 'kitchen': 36,\n",
       " 'sandra': 37}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8808c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Activation,Dense,Permute,Dropout,add,dot,concatenate,LSTM,Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "248f7ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7eabe7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence= Input((max_story_len,))\n",
    "question = Input((max_question_len,))\n",
    "vocab_size = len(vocab)+1\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim= vocab_size,output_dim=64))\n",
    "# 30% of neurons are dropped while training\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "# samples,story_max_len,embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b71c4e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim= vocab_size,output_dim=max_question_len))\n",
    "# 30% of neurons are dropped while training\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# samples,story_max_len,max_question_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5cbbd69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim= vocab_size,output_dim=64,input_length=max_question_len))\n",
    "# 30% of neurons are dropped while training\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# samples,story_max_len,embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "05104a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d3dee3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 86, 150) dtype=float32 (created by layer 'concatenate_3')>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match = dot([input_encoded_m,question_encoded],axes=(2,2))\n",
    "match = Activation('softmax')(match)\n",
    "response = add([match,input_encoded_c])\n",
    "response = Permute((2,1))(response)\n",
    "answer = concatenate([response,question_encoded])\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b385ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)\n",
    "answer = Activation('softmax')(answer)\n",
    "model = Model([input_sequence,question],answer)\n",
    "model.compile(optimizer ='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20b503c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 86)]         0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 86)]         0           []                               \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)      (None, None, 64)     2432        ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_6 (Sequential)      (None, 86, 64)       2432        ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dot_3 (Dot)                    (None, 86, 86)       0           ['sequential_4[0][0]',           \n",
      "                                                                  'sequential_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 86, 86)       0           ['dot_3[0][0]']                  \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)      (None, None, 86)     3268        ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 86, 86)       0           ['activation_3[0][0]',           \n",
      "                                                                  'sequential_5[0][0]']           \n",
      "                                                                                                  \n",
      " permute_3 (Permute)            (None, 86, 86)       0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 86, 150)      0           ['permute_3[0][0]',              \n",
      "                                                                  'sequential_6[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 32)           23424       ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 32)           0           ['lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 38)           1254        ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 38)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32,810\n",
      "Trainable params: 32,810\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "556b0a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 2s 71ms/step - loss: 0.2990 - accuracy: 0.8640 - val_loss: 0.2854 - val_accuracy: 0.8670\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.2907 - accuracy: 0.8780 - val_loss: 0.2791 - val_accuracy: 0.8700\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 0.2963 - accuracy: 0.8550 - val_loss: 0.2030 - val_accuracy: 0.9110\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.2936 - accuracy: 0.8650 - val_loss: 0.2465 - val_accuracy: 0.8670\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.2564 - accuracy: 0.8830 - val_loss: 0.1984 - val_accuracy: 0.9070\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 0.3100 - accuracy: 0.8570 - val_loss: 0.2063 - val_accuracy: 0.9000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2827 - accuracy: 0.8620 - val_loss: 0.1855 - val_accuracy: 0.9180\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.2666 - accuracy: 0.8750 - val_loss: 0.2050 - val_accuracy: 0.9010\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.2859 - accuracy: 0.8710 - val_loss: 0.2629 - val_accuracy: 0.8830\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.2704 - accuracy: 0.8740 - val_loss: 0.1811 - val_accuracy: 0.9140\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2735 - accuracy: 0.8790 - val_loss: 0.1906 - val_accuracy: 0.9110\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.2696 - accuracy: 0.8840 - val_loss: 0.2685 - val_accuracy: 0.8840\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.2594 - accuracy: 0.8780 - val_loss: 0.1699 - val_accuracy: 0.9230\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.2618 - accuracy: 0.8830 - val_loss: 0.1684 - val_accuracy: 0.9200\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2405 - accuracy: 0.8870 - val_loss: 0.2311 - val_accuracy: 0.8880\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.2496 - accuracy: 0.8940 - val_loss: 0.2127 - val_accuracy: 0.9020\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.2283 - accuracy: 0.8890 - val_loss: 0.1962 - val_accuracy: 0.9010\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.2274 - accuracy: 0.8900 - val_loss: 0.1878 - val_accuracy: 0.9140\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 0.2489 - accuracy: 0.8850 - val_loss: 0.2169 - val_accuracy: 0.8950\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.2228 - accuracy: 0.9070 - val_loss: 0.1724 - val_accuracy: 0.9280\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.2684 - accuracy: 0.8940 - val_loss: 0.1577 - val_accuracy: 0.9400\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 0.2111 - accuracy: 0.9030 - val_loss: 0.1688 - val_accuracy: 0.9150\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.2193 - accuracy: 0.9000 - val_loss: 0.2479 - val_accuracy: 0.8910\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 0.2478 - accuracy: 0.8860 - val_loss: 0.1494 - val_accuracy: 0.9330\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 0.2306 - accuracy: 0.8800 - val_loss: 0.1618 - val_accuracy: 0.9260\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.2157 - accuracy: 0.9140 - val_loss: 0.1480 - val_accuracy: 0.9350\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.2322 - accuracy: 0.9080 - val_loss: 0.2588 - val_accuracy: 0.8920\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 0.2190 - accuracy: 0.9020 - val_loss: 0.4973 - val_accuracy: 0.8140\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 0.2295 - accuracy: 0.8990 - val_loss: 0.1397 - val_accuracy: 0.9410\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 2s 52ms/step - loss: 0.1895 - accuracy: 0.9220 - val_loss: 0.1331 - val_accuracy: 0.9450\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.1780 - accuracy: 0.9210 - val_loss: 0.1492 - val_accuracy: 0.9160\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.2118 - accuracy: 0.9050 - val_loss: 0.1421 - val_accuracy: 0.9380\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 0.2169 - accuracy: 0.9140 - val_loss: 0.1479 - val_accuracy: 0.9410\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.1899 - accuracy: 0.9230 - val_loss: 0.1257 - val_accuracy: 0.9540\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.2077 - accuracy: 0.9110 - val_loss: 0.1084 - val_accuracy: 0.9560\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.1890 - accuracy: 0.9160 - val_loss: 0.1151 - val_accuracy: 0.9500\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.1893 - accuracy: 0.9230 - val_loss: 0.1498 - val_accuracy: 0.9340\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 0.1966 - accuracy: 0.9160 - val_loss: 0.1282 - val_accuracy: 0.9390\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.1832 - accuracy: 0.9260 - val_loss: 0.1588 - val_accuracy: 0.9390\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.2054 - accuracy: 0.9160 - val_loss: 0.1255 - val_accuracy: 0.9490\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1724 - accuracy: 0.9330 - val_loss: 0.1514 - val_accuracy: 0.9330\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1910 - accuracy: 0.9300 - val_loss: 0.1142 - val_accuracy: 0.9570\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1559 - accuracy: 0.9290 - val_loss: 0.2142 - val_accuracy: 0.9090\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1935 - accuracy: 0.9230 - val_loss: 0.0992 - val_accuracy: 0.9600\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.1558 - accuracy: 0.9320 - val_loss: 0.1219 - val_accuracy: 0.9490\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 0.1595 - accuracy: 0.9270 - val_loss: 0.1148 - val_accuracy: 0.9510\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.2083 - accuracy: 0.9230 - val_loss: 0.1374 - val_accuracy: 0.9470\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1734 - accuracy: 0.9280 - val_loss: 0.0928 - val_accuracy: 0.9620\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1463 - accuracy: 0.9490 - val_loss: 0.0999 - val_accuracy: 0.9560\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1611 - accuracy: 0.9310 - val_loss: 0.0966 - val_accuracy: 0.9560\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1425 - accuracy: 0.9320 - val_loss: 0.1111 - val_accuracy: 0.9550\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1534 - accuracy: 0.9390 - val_loss: 0.0948 - val_accuracy: 0.9590\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 0.1636 - accuracy: 0.9280 - val_loss: 0.1136 - val_accuracy: 0.9530\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 0.1614 - accuracy: 0.9290 - val_loss: 0.0998 - val_accuracy: 0.9600\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 0.1510 - accuracy: 0.9390 - val_loss: 0.0903 - val_accuracy: 0.9600\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1482 - accuracy: 0.9420 - val_loss: 0.0812 - val_accuracy: 0.9740\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.1626 - accuracy: 0.9350 - val_loss: 0.0871 - val_accuracy: 0.9620\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 48ms/step - loss: 0.1520 - accuracy: 0.9390 - val_loss: 0.0675 - val_accuracy: 0.9750\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 0.1446 - accuracy: 0.9360 - val_loss: 0.0973 - val_accuracy: 0.9510\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.1413 - accuracy: 0.9520 - val_loss: 0.0906 - val_accuracy: 0.9600\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.1577 - accuracy: 0.9410 - val_loss: 0.0909 - val_accuracy: 0.9640\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 0.1522 - accuracy: 0.9350 - val_loss: 0.0723 - val_accuracy: 0.9730\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.1356 - accuracy: 0.9490 - val_loss: 0.0857 - val_accuracy: 0.9610\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1517 - accuracy: 0.9410 - val_loss: 0.2193 - val_accuracy: 0.9360\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.1492 - accuracy: 0.9440 - val_loss: 0.0774 - val_accuracy: 0.9660\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.1389 - accuracy: 0.9480 - val_loss: 0.0589 - val_accuracy: 0.9810\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.1748 - accuracy: 0.9450 - val_loss: 0.1046 - val_accuracy: 0.9620\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.1442 - accuracy: 0.9500 - val_loss: 0.0660 - val_accuracy: 0.9800\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.1338 - accuracy: 0.9510 - val_loss: 0.0841 - val_accuracy: 0.9600\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.1268 - accuracy: 0.9550 - val_loss: 0.0729 - val_accuracy: 0.9710\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.1696 - accuracy: 0.9330 - val_loss: 0.0574 - val_accuracy: 0.9850\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.1044 - accuracy: 0.9570 - val_loss: 0.0856 - val_accuracy: 0.9560\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.1582 - accuracy: 0.9480 - val_loss: 0.0574 - val_accuracy: 0.9800\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.1142 - accuracy: 0.9500 - val_loss: 0.0540 - val_accuracy: 0.9840\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.1260 - accuracy: 0.9540 - val_loss: 0.0573 - val_accuracy: 0.9800\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.0996 - accuracy: 0.9630 - val_loss: 0.1091 - val_accuracy: 0.9520\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.1331 - accuracy: 0.9520 - val_loss: 0.0503 - val_accuracy: 0.9850\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.1072 - accuracy: 0.9600 - val_loss: 0.2518 - val_accuracy: 0.9050\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.1261 - accuracy: 0.9560 - val_loss: 0.1131 - val_accuracy: 0.9510\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.1270 - accuracy: 0.9490 - val_loss: 0.0907 - val_accuracy: 0.9560\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.1098 - accuracy: 0.9530 - val_loss: 0.0849 - val_accuracy: 0.9720\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.1065 - accuracy: 0.9640 - val_loss: 0.0454 - val_accuracy: 0.9880\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0910 - accuracy: 0.9610 - val_loss: 0.0792 - val_accuracy: 0.9650\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0975 - accuracy: 0.9600 - val_loss: 0.1465 - val_accuracy: 0.9430\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.1206 - accuracy: 0.9550 - val_loss: 0.0492 - val_accuracy: 0.9840\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.1065 - accuracy: 0.9620 - val_loss: 0.0753 - val_accuracy: 0.9640\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.0918 - accuracy: 0.9620 - val_loss: 0.0456 - val_accuracy: 0.9840\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.0942 - accuracy: 0.9610 - val_loss: 0.0365 - val_accuracy: 0.9910\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.0913 - accuracy: 0.9680 - val_loss: 0.0852 - val_accuracy: 0.9650\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.1002 - accuracy: 0.9690 - val_loss: 0.0442 - val_accuracy: 0.9850\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.1097 - accuracy: 0.9600 - val_loss: 0.0451 - val_accuracy: 0.9880\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.1036 - accuracy: 0.9660 - val_loss: 0.0382 - val_accuracy: 0.9870\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.1001 - accuracy: 0.9680 - val_loss: 0.1166 - val_accuracy: 0.9360\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.0996 - accuracy: 0.9660 - val_loss: 0.1011 - val_accuracy: 0.9640\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.0894 - accuracy: 0.9730 - val_loss: 0.0289 - val_accuracy: 0.9900\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.1111 - accuracy: 0.9610 - val_loss: 0.0371 - val_accuracy: 0.9850\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.1020 - accuracy: 0.9660 - val_loss: 0.0352 - val_accuracy: 0.9830\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.0910 - accuracy: 0.9630 - val_loss: 0.0303 - val_accuracy: 0.9920\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.0947 - accuracy: 0.9670 - val_loss: 0.0289 - val_accuracy: 0.9900\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.1119 - accuracy: 0.9670 - val_loss: 0.0567 - val_accuracy: 0.9700\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train,query_train],answer_train,batch_size=32,epochs=100,validation_data=([inputs_train,query_train],answer_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2cba9b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isita/Downloads/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "model.save('my_chatbot.h5')\n",
    "model.load_weights('my_chatbot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "66fae1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([inputs_test,query_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4e9f936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.6935620e-13, 1.3406125e-13, 1.8088013e-13, 1.3913018e-13,\n",
       "       1.3542904e-13, 1.7183101e-13, 1.7514122e-13, 1.8193268e-13,\n",
       "       1.6109980e-13, 1.5104281e-13, 1.4737347e-13, 1.5203072e-13,\n",
       "       1.5363105e-13, 1.9439390e-13, 1.8451523e-13, 1.3260660e-13,\n",
       "       1.2069087e-13, 2.0295359e-13, 1.3278477e-13, 1.4106693e-13,\n",
       "       1.5198665e-13, 1.6825378e-13, 1.3300885e-13, 1.2696490e-13,\n",
       "       9.9538773e-01, 1.6235589e-13, 4.6122619e-03, 1.8926883e-13,\n",
       "       1.2463082e-13, 1.4168120e-13, 1.1927339e-13, 1.6716108e-13,\n",
       "       1.5452857e-13, 1.4337370e-13, 1.2092405e-13, 1.2918933e-13,\n",
       "       1.9927881e-13, 1.3922468e-13], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e8e1ec51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e933eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in tokenizer.word_index.items():\n",
    "    if value==np.argmax(pred_results[0]):\n",
    "        k =key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0bd7697a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "40403975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99538773"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[0][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dd77d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = 'John left the football in the kitchen'\n",
    "question ='Is the football in the kitchen ?'\n",
    "answer = 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7ff825a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = [(story.split(),question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fa1b1b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['John', 'left', 'the', 'football', 'in', 'the', 'kitchen'],\n",
       "  ['Is', 'the', 'football', 'in', 'the', 'kitchen', '?'],\n",
       "  'yes')]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "72591780",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story, my_ques, my_ans = vector_stories(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "95f47883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 28,\n",
       "         2, 32,  3,  2, 36, 30]], dtype=int32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "68ebbf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "199b27cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(([my_story,my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e790c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ef81dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in tokenizer.word_index.items():\n",
    "    if value == val_max:\n",
    "        k = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b26856e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a017e61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7602364"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ec772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
