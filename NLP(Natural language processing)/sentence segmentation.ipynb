{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f17cb805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfac357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp= spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cdd52fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('First sentence.Second sentence.Third sentence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac86bd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence.\n",
      "Second sentence.\n",
      "Third sentence.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf846b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_boundaries(doc):\n",
    "    for token in doc:\n",
    "        print(token)\n",
    "        print(token.i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f629da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First\n",
      "0\n",
      "sentence\n",
      "1\n",
      ".\n",
      "2\n",
      "Second\n",
      "3\n",
      "sentence\n",
      "4\n",
      ".\n",
      "5\n",
      "Third\n",
      "6\n",
      "sentence\n",
      "7\n",
      ".\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "custom_boundaries(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e479ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing things right; leadership is doing the right things.\"\n",
      "-Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n",
    "\n",
    "for sent in doc3.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "943a1e65",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E007] 'fun1' already exists in pipeline. Existing names: ['tok2vec', 'tagger', 'fun1', 'parser', 'senter', 'attribute_ruler', 'lemmatizer', 'ner']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/77/62vqfsnn1zq824lb1thq0zb80000gn/T/ipykernel_3317/1562159833.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fun1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/anaconda3/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfactory_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE007\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;31m# We're loading the component from a model. After loading the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E007] 'fun1' already exists in pipeline. Existing names: ['tok2vec', 'tagger', 'fun1', 'parser', 'senter', 'attribute_ruler', 'lemmatizer', 'ner']"
     ]
    }
   ],
   "source": [
    "# ADD A NEW RULE TO THE PIPELINE\n",
    "from spacy.language import Language\n",
    "\n",
    "@Language.component(\"fun1\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == ';':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "\n",
    "nlp.add_pipe('fun1', before='parser')\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "626bb34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing things right;\n",
      "leadership is doing the right things.\"\n",
      "-Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n",
    "for sent in doc4.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99241efc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (952484127.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/77/62vqfsnn1zq824lb1thq0zb80000gn/T/ipykernel_3317/952484127.py\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    NewLineSegmenter().set_sent_starts()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# splits on new lines\n",
    "from seg.newline.segmenter import NewLineSegmenter\n",
    "\n",
    "\n",
    "@Language.component(\"set_sent_starts\")\n",
    "NewLineSegmenter().set_sent_starts()\n",
    "\n",
    "nlp.add_pipe('set_sent_starts', before='parser')\n",
    "\n",
    "doc5 = nlp(u\"This is a sentence. This is another.\\n\\nThis is a \\nthird sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "563de009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.split_on_newline(doc)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@Language.component(\"set_sent_starts\")\n",
    "def split_on_newline(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == '\\n':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe('set_sent_starts', before='parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a53ccdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc5 = nlp(u\"This is \\n a sentence. This is \\n another\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44501571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is \n",
       " a sentence. This is \n",
       " another"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e935d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'fun1', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d709c474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('set_sent_starts', <function __main__.split_on_newlines(doc)>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.remove_pipe(\"set_sent_starts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe1690c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
